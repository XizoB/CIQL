# @package _global_

agent:
  name: sac
  _target_: agent.sac.SAC
  obs_dim: ??? # to be specified later
  action_dim: ??? # to be specified later

  critic_cfg: ${q_net}  # 跳转到q_net参数
  detached_critic_cfg: ${detached_q_net}  # 跳转到detached_q_net参数
  actor_cfg: ${diag_gaussian_actor}  # 跳转到diag_gaussian_actor参数
  init_temp: 1e-2 # use a low temp for IL, 初始化自动调节正则化参数alpha

  alpha_lr: 3e-4
  alpha_betas: [0.9, 0.999]

  actor_lr: 3e-4
  actor_betas: [0.9, 0.999]
  actor_update_frequency: 1  # 策略网络更新频率

  critic_lr: 3e-4
  critic_betas: [0.9, 0.999]
  critic_tau: 0.005  # SAC的价值网络的软更新tau参数
  critic_target_update_frequency: 1  # 目标价值网络更新频率
  num_actor_updates: 1                        # 策略网络每次更新(更新频率)的更新步数
  

  # learn temperature coefficient (disabled by default) 学习温度系数
  learn_temp: false

  # Use either value_dice actor or normal SAC actor loss
  vdice_actor: false

q_net:
  _target_: agent.sac_models.DoubleQCritic
  obs_dim: ${agent.obs_dim}
  action_dim: ${agent.action_dim}
  hidden_dim: 256
  hidden_depth: 2

diag_gaussian_actor:
  _target_: agent.sac_models.DiagGaussianActor
  obs_dim: ${agent.obs_dim}
  action_dim: ${agent.action_dim}
  hidden_dim: 256
  hidden_depth: 2
  log_std_bounds: [-5, 2]

detached_q_net:
  _target_: agent.sac_models.SingelDetachedCritic
  obs_dim: ${agent.obs_dim}
  action_dim: ${agent.action_dim}
  hidden_dim: 256
  hidden_depth: 2